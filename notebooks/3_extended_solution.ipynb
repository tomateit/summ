{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Papers that somewhat resemble my ideas or just may be useful*:  \n",
    "+ [Neural Extractive Text Summarization with Syntactic Compression](https://aclanthology.org/D19-1324.pdf) *by Jiacheng Xu and Greg Durrett*:\n",
    "    + The approach encodes the text and *then* performs the compression;\n",
    "    + https://github.com/jiacheng-xu/neu-compression-sum (gosh, what a horrible code)\n",
    "+ [Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting](https://aclanthology.org/P18-1063.pdf) *by Yen-Chun Chen and Mohit Bansal*:\n",
    "    + This approach utilizes RL to rewrite sents, along with abstractive summarization;\n",
    "    + https://github.com/ChenRocks/fast_abs_rl (much more readable repo)\n",
    "+ [Extractive Summarization as Text Matching](https://arxiv.org/pdf/2004.08795v1.pdf) *by Ming Zhong, Pengfei Liu, Yiran Chen, Danqing Wang, Xipeng Qiu, Xuanjing Huang*:\n",
    "    + https://github.com/maszhongming/MatchSum\n",
    "    + CNN/DailyMail to a new level (44.41 in ROUGE-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work structure\n",
    "#### 1. Dataset loading and preprocessing\n",
    "\n",
    "#### 2. Implementing heuristics as standalone preprocessing functionality\n",
    "This work suggest usiing some preprocessing tricks to improve the actual effect of summarization. The following ways are suggested (each is to be implemented in separate notebook):\n",
    "1. Utilize coreference resolution among sentences so we won't miss important nouns in our summary.\n",
    "2. Try to split compound sentences into few smaller ones.\n",
    "3. Compress resulting sentences so we exclude some low-informative words without (hopefully) sacrifising the readability.\n",
    "    - Named entities intuitively seem more important that common nouns, so they are not to be deleted.\n",
    "    \n",
    "#### 3. Implementation of summarization block per-se\n",
    "#### 4. Evaluation and metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here: https://cs.nyu.edu/~kcho/DMQA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will still be using the same The New Yorker chunk as it's grammatical structure is quite diverse.\n",
    "body = \"Resonance is the literary magazine put out by the students of Falmouth Academy, the Massachusetts private school I attended for six years, starting in the seventh grade. During my time at F.A., I had at least one poem published in each issue of Resonance. In high school, I was also a member of the staff. But that wasn’t why I loved it. I loved it — and I swear I am not exaggerating here — because I thought the writing in its pages was more beautiful than anything I’d ever read. I was not a happy or popular adolescent, and the emotional stance I adopted toward most of my peers at F.A. might best be described as a defensive crouch. I was scared of my classmates, and I resented them; I could tell they didn’t like me, but I couldn’t figure out why. To the extent that I was able to lift myself out of my own sodden self-loathing to contemplate their inner worlds, I imagined their minds to be filled, like mine, with a whirlwind of criticism and judgment. But, once a year, at the end of the spring semester, I would open my copy of Resonance and be forced to face the unsettling possibility that my classmates were not the shallow bullies I imagined them to be but actual people, with souls.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = \"The things are quite complicated, we shall move on.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the sentence with the spacy engine:\n",
    "doc = nlp(body)\n",
    "sentences = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarization block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my summarization block I'd like to make use of the novel method suggested by \n",
    "\n",
    "The main keypoint of the work:\n",
    "> Instead of scoring and extracting sentences\n",
    "> one by one to form a summary, we formulate\n",
    "> extractive summarization as a semantic text matching\n",
    "> problem and propose a novel summary-level\n",
    "> framework. Our approach bypasses the difficulty\n",
    "> of summary-level optimization by contrastive learning,\n",
    "> that is, a good summary should be more\n",
    "> semantically similar to the source document than the\n",
    "> unqualified summaries.\n",
    "\n",
    "*IMO, it resembles the centroidal approach from my baseline, but I cannot loose the chance to use some deep learning for that ;-)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Inspired by siamese network structure (Bromley\n",
    "et al., 1994), we construct a Siamese-BERT archi\n",
    "tecture to match the document D and the candidate\n",
    "summary C. Our Siamese-BERT consists of two\n",
    "BERTs with tied-weights and a cosine-similarity\n",
    "layer during the inference phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we will need some BERT...\n",
    "> we use the vector of the ‘[CLS]’ token from the top BERT layer as the representation of a document or summary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare simiarities...\n",
    "> Let $r_D$ and $r_C$ denote the embeddings of the document D and candidate summary C. Their similarity score is measured by\n",
    "$f(D,C) = cosine(r_D,r_C)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the loss...\n",
    "> In order to fine-tune Siamese-BERT, we use a margin-based triplet loss to update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't search though all possible candidates can be of $\\sum_{i=1}^{n}C_n^i$ variants? We'll see.\n",
    "> In the inference phase, we formulate extractive summarization as a task to search for the best summary among all the candidates C extracted from the document D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and yeah, exactly:\n",
    "> The matching idea is more intuitive while it suffers from combinatorial explosion problems. \\[...] we introduce a content selection module to pre-select salient sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Eval and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python381064bitvenvvenvc5206c77ee25436a9af873d7e9575275"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
