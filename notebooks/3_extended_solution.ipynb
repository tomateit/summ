{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Papers that somewhat resemble my ideas or just may be useful*:  \n",
    "+ [Neural Extractive Text Summarization with Syntactic Compression](https://aclanthology.org/D19-1324.pdf) *by Jiacheng Xu and Greg Durrett*:\n",
    "    + The approach encodes the text and *then* performs the compression;\n",
    "    + https://github.com/jiacheng-xu/neu-compression-sum (gosh, what a horrible code)\n",
    "+ [Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting](https://aclanthology.org/P18-1063.pdf) *by Yen-Chun Chen and Mohit Bansal*:\n",
    "    + This approach utilizes RL to rewrite sents, along with abstractive summarization;\n",
    "    + https://github.com/ChenRocks/fast_abs_rl (much more readable repo)\n",
    "+ [Extractive Summarization as Text Matching](https://arxiv.org/pdf/2004.08795v1.pdf) *by Ming Zhong, Pengfei Liu, Yiran Chen, Danqing Wang, Xipeng Qiu, Xuanjing Huang*:\n",
    "    + https://github.com/maszhongming/MatchSum\n",
    "    + CNN/DailyMail to a new level (44.41 in ROUGE-1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work structure\n",
    "#### 1. Dataset loading and preprocessing\n",
    "\n",
    "#### 2. Implementing heuristics as standalone preprocessing functionality (postponed)\n",
    "This work suggest usiing some preprocessing tricks to improve the actual effect of summarization. \n",
    "The following ways are suggested (each is to be implemented in separate notebook):\n",
    "1. Utilize coreference resolution among sentences so we won't miss important nouns in our summary.\n",
    "2. Try to split compound sentences into few smaller ones.\n",
    "3. Compress resulting sentences so we exclude some low-informative words without (hopefully) sacrifising the readability.\n",
    "    - Named entities intuitively seem more important that common nouns, so they are not to be deleted.\n",
    "    \n",
    "#### 3. Implementation of summarization block per-se\n",
    "#### 4. Evaluation and metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here: https://cs.nyu.edu/~kcho/DMQA/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Heuristics (postponed)\n",
    "\n",
    "See notebooks 3.1, 3.2, 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarization block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my summarization block I'd like to make use of the novel method suggested by \n",
    "\n",
    "The main keypoint of the work:\n",
    "> Instead of scoring and extracting sentences\n",
    "> one by one to form a summary, we formulate\n",
    "> extractive summarization as a semantic text matching\n",
    "> problem and propose a novel summary-level\n",
    "> framework. Our approach bypasses the difficulty\n",
    "> of summary-level optimization by contrastive learning,\n",
    "> that is, a good summary should be more\n",
    "> semantically similar to the source document than the\n",
    "> unqualified summaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Inspired by siamese network structure (Bromley\n",
    "et al., 1994), we construct a Siamese-BERT archi\n",
    "tecture to match the document D and the candidate\n",
    "summary C. Our Siamese-BERT consists of two\n",
    "BERTs with tied-weights and a cosine-similarity\n",
    "layer during the inference phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we will need some BERT...\n",
    "> we use the vector of the ‘\\[CLS]’ token from the top BERT layer as the representation of a document or summary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also compare simiarities...\n",
    "> Let $r_D$ and $r_C$ denote the embeddings of the document D and candidate summary C. Their similarity score is measured by\n",
    "$f(D,C) = cosine(r_D,r_C)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the loss...\n",
    "> In order to fine-tune Siamese-BERT, we use a margin-based triplet loss to update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't search though all possible candidates can be of $\\sum_{i=1}^{n}C_n^i$ variants?\n",
    "> In the inference phase, we formulate extractive summarization as a task to search for the best summary among all the candidates C extracted from the document D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and yeah, exactly:\n",
    "> The matching idea is more intuitive while it suffers from combinatorial explosion problems. \\[...] we introduce a content selection module to pre-select salient sentences.\n",
    "\n",
    "Abovementioned content selection is done via [PreSumm](https://github.com/nlpyang/PreSumm) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### May be useful:\n",
    "+ \"We truncate each document to 512 tokens and feed them to MatchSum because the pre-trained models (BERT, RoBERTa) has a maximum length limit.\" [github](https://github.com/maszhongming/MatchSum/issues/9#issuecomment-637904607)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Suggested flow\n",
    "The paper suggests the following workflow:\n",
    "1. You score the sentences of the input text with some third-party model accordingly to their presumed informational contribution to the meaning of a text.\n",
    "2. You get some summary candidates based on combinatorial allocations (hyperparam-dependednt, so you can affect the number of output sentences) with respect to the top scores from the step 1.\n",
    "3. The deeplearning model learns to choose the best one from the summaries, at the same time avoiding common pitfalls of usual models (the authors of the paper suggest \"pearl-summary vs. best-summary\" problem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\[Preparation] Creating dataset\n",
    "\n",
    "The dataset I will use needs to be in a certain form. The original solution suggests jsonl format with json objects separated by newline token.\n",
    "I don't mind it. \n",
    "\n",
    "So, first of all, I preprocess and convert my dataset into suitable format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No code here for now, refer to `dataset_utils/cnndm_preprocessor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also I truncate the dataset to 10k first docs. The original paper states that the training took 30 hours with several top GPUs. I have none."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are suggested to somehow score our sentences by their importance. I will use trivial method for that, and also I will not truncate my input on this stage, as long as it can be a hyperparam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " > - truncate each document into the 5 most important sentences (using BertExt), \n",
    "   then select any 2 or 3 sentences to form a candidate summary, so there are C(5,2)+C(5,3)=20 candidate summaries.\n",
    "   if you want to process other datasets, you may need to adjust these numbers according to specific situation.\n",
    "\n",
    "BertExt has very questionable codebase and maintainment, so I will stuck with centroidal sorting for this case.\n",
    "Moreover, I will use not Bert or RoBERTa, but LaBSE simply because I've already used.\n",
    "Thus, if my integrated encoder will be LaBSE, why shouldn't I just utilize it to create ranking of the sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No code here for now, refer to `dataset_utils/create_sentence_ranking`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loader\n",
    "The dataset loader was recreated inspired by the MatchSum repo, but with much more readable variable names and with use of torch Dataset instead of any relation on fastNLP (wtf?) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataset_utils.dataset import CNNDMDataset\n",
    "\n",
    "textual_file_path = Path(\"../data/cnndm/dataset10k.jsonl\")\n",
    "indices_file_path = Path(\"../data/cnndm/sent_id10k.jsonl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Eval and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python381064bitvenvvenvc5206c77ee25436a9af873d7e9575275"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
